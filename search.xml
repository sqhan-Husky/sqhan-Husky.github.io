<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>FirstArticle</title>
    <url>/2020/08/03/FirstArticle/</url>
    <content><![CDATA[<p>Welcome to Siqi’s Blog.</p>
<p>I’m READY.</p>
]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>Life</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_A Survey of Machine Learning for Big Code and Naturalness</title>
    <url>/2020/08/05/Big-code-survey/</url>
    <content><![CDATA[<blockquote>
<p>NLP技术发展至今，在代码领域的挖掘也逐步深入，近期针对Code Naturalness阅读了一些论文和技术，于是想从这篇比较全面的<a href="https://arxiv.org/abs/1709.06182v1">survey</a>入手，梳理一下整个代码处理的发展史，形成一个整体概念。本文偏向于提纲式的整理。</p>
</blockquote>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><strong>Objective</strong> —— <em>There is therefore an ongoing demand for innovations in software tools that help make software more reliable and maintainable.</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;生活的方方面面都依赖着高质量软件的可靠操作，但是软件的维护是代价大复杂程度高且耗时的过程，这就要求着工具的不断改进来降低软件的复杂度，同时帮助工程师更好的维护代码。</p>
<p><strong>Big Code</strong> —— <em>The scale of available data is massive.</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;系统源码的庞大，各类元数据(authorship, bug-fixes, reviews)的繁多，暗示了一种新的数据驱动的开发软件工具的办法：在大型且有代表性的软件集上进行统计分布估算，从而能在大多数情况下取得好的结果。</p>
<blockquote>
<p>原文中，后两个概念出现在第二部分中，但我把它们提到前面来，进行简要的阐释。如果想要更详细的内容，请阅读原论文~</p>
</blockquote>
<p><strong>The Naturalness Hypothesis</strong> —— <em>Software is a form of human communication; software corpora have similar statistical properties to natural language corpora; and these properties can be exploited to build better software engineering tools.</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;软件是人类交流的一种形式，软件语料库具有和自然语言语料库相似的统计特征，这些特征可以利用在建立更好的软件工具上。基于这个假设，就可以使用机器学习的方法来设计模型学习开发者们是如何写代码使用代码的。</p>
<p><strong>Code Predictability</strong> —— <em>Code is conventional, idiomatic, and familiar.</em></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;代码书写存在规律性和习惯性，因此概率统计模型可以针对代码学习出有效的特征，给出相应任务的反馈。</p>
<h2 id="Text-Code-and-Machine-Learning"><a href="#Text-Code-and-Machine-Learning" class="headerlink" title="Text, Code and Machine Learning"></a>Text, Code and Machine Learning</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;程序语言代码是人类和计算机沟通交流的媒介，尽管代码和文本间存在许多相似，但是代码对于目前存在的ML和NLP技术来说仍然是相对较新的问题领域。因此，仔细枚举出代码和文本间的差异有利于学习到通过修改现有的NLP技术来处理代码的适当方法。</p>
<ul>
<li><strong>Executability</strong></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所有代码都是可执行的，代码通常在语义上敏感，很小的改动也会使得代码的表达产生很大的变化；而读者面对自然语言时也能理解可能错误的地方。所以代码语义对于噪声的敏感性需要将概率方法和形式方法结合起来，例如应用严格的形式限制来过滤概率模型的输出。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另一方面，编程语言可以在多种语言中互通转换，所有的主流语言都是Turing-complete的，即将现实世界的语言移植到新的语言和平台可行但极具挑战的。现有的ML技术能达到的是在语法相近的Java语言和C#语言上完成转换。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;代码的可执行性在程序中引起控制和数据流，并且赋予代码有静态代码和动态视图（例如执行轨迹）的两种形式。  </p>
<ul>
<li><strong>Formality</strong></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;程序设计语言是形式化的语言，自上而下地设计给使用者们。源代码在局部上模式更密集，支持被重复使用，可将常用功能归入库函数中。同时，因为程序语言需要自动的翻译为机器语言，因此保有较好的语法性，以及丰富而明确的代码结构，可以被大麦的概率模型很好地利用。</p>
<ul>
<li><strong>Cross-Channel Interation</strong></li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;代码中自然的语义单元通常有标识符、语句、代码块和函数，而这些很难被映射到文本语义单元上。相对于文本而言，代码函数的抽象语法树通常更深且有更多重复的内部结构。在代码库中，不同的任务被描述成不同的语言，且比文本有更高的新词率。</p>
<h2 id="Probablistic-Models-of-Code"><a href="#Probablistic-Models-of-Code" class="headerlink" title="Probablistic Models of Code"></a>Probablistic Models of Code</h2><blockquote>
<p>这一章节关注到许多关于源代码的概率机器学习模型，总共列举了许多上百种方法。在这里我就不展开详细介绍每一种方法，之后有时间会多介绍几个自己研究过的模型，主要会集中在第二个模型类别里，大家可以自己找感兴趣的模型学习。</p>
</blockquote>
<p>基于模型概率分布等式的形式和输入输出的形式，作者对模型进行了分类，而每一类模型下会继续细分。</p>
<h3 id="Code-generating-Models"><a href="#Code-generating-Models" class="headerlink" title="Code-generating Models"></a>Code-generating Models</h3><p>“Code-generating Models define a probability distribution over code by stochastically modeling the generation of smaller and simpler parts of code, e.g. tokens or AST nodes.”  </p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这一类模型在于预测复杂的代码结构，他们会对生成过程做一些简化的假设，并迭代地预测代码中的元素来生成一个完整的代码单元。因为代码结构的复杂度和假设的存在性，想要生成可编译可执行的代码是有难度的。  </p>
<p>从模型生成过程中所用的代码粒度来说:  </p>
<ul>
<li>Token-level Models(sequences)<br>这类模型把代码看做一组元素的序列，有序地来依次进行预测任务。序列中常用的n-gram模型在捕获局部和简单的依赖十分有效，但是对于代码来说，代码更冗长，且光靠代码上文会丢失很多信息，因此，许多方法在使用n-gram模型的基础上尝试了许多改进。当循环深度神经网络在序列问题上表现成功后，也被应用到了代码模型上，不过比n-gram模型需要更多的数据。</li>
<li>Syntactic Models(trees)</li>
<li>Semantic Models(graphs)</li>
</ul>
<p>从模型的输出目的来说:</p>
<ul>
<li>Language Models</li>
<li>Code Transducer Models</li>
<li>Multimodal Models</li>
</ul>
<h3 id="Representational-Models-of-Code"><a href="#Representational-Models-of-Code" class="headerlink" title="Representational Models of Code"></a>Representational Models of Code</h3><p>“Representational Models of Code take an abstract representation4 of code as input. Example representations include token contexts or data flow. The resulting model yields a conditional probability distribution over code element properties, like the types of variables, and can predict them.”  </p>
<h3 id="Pattern-Mining-Models"><a href="#Pattern-Mining-Models" class="headerlink" title="Pattern Mining Models"></a>Pattern Mining Models</h3><p>“Pattern Mining Models infer, without supervision, a likely latent structure within code. These models are an instantiation of clustering in the code domain; they can find reusable and human-interpretable patterns.”</p>
]]></content>
      <categories>
        <category>Big Code</category>
      </categories>
      <tags>
        <tag>paper</tag>
        <tag>Code Naturalness</tag>
      </tags>
  </entry>
  <entry>
    <title>【分布式系统_1】 文件系统</title>
    <url>/2020/08/05/Distributed-System-1/Distributed-System-1/</url>
    <content><![CDATA[<blockquote>
<p>分布式系统课件1：分布式文件系统，从文件系统入手，进一步介绍分布式文件系统。</p>
</blockquote>
<h3 id="文件系统-FS）"><a href="#文件系统-FS）" class="headerlink" title="文件系统(FS）"></a>文件系统(FS）</h3><pre><code>1. 文件系统概述  
文件系统：操作系统中负责管理和存取信息的模块  
• 基本功能：  
  1）文件的按名存取  
  2）文件目录的建立和维护  
  3）实现逻辑文件到物理文件的转换（核心）  
  4）文件存储空间的分配和管理  
  5）数据保密、保护和共享  
  6）提供一组用户使用的操作  

2. 文件与目录
• 实现按名存取的文件系统的优点：
  1）将用户从复杂的屋里存储地址管理中解放出来
  2）可方便地对文件提供各种安全、保密和保护措施
  3）实现文件的共享（同名共享、异名共享）

• 如何实现按名存取？
  当用户要求存取某个文件时，系统查找目录文件，获得对应的文件目录
  在文件目录中，根据用户给定的文件名寻找到对应文件的文件控制块（文件目录项）
  通过文件控制块所记录的该文件的相关信息依次存取该文件的内容

• 文件目录
  1）文件目录：建立和维护的关于系统的所有文件的清单
  2）文件控制块：每个目录项对应一个文件的信息描述（存取控制信息、结构信息、使用信息、管理信息）
  3）目录文件：目录信息也以文件的形式存放

• 树形目录结构

3. 文件的物理结构
• 文件在物理存储中的存放方法和组织关系
  块（物理记录）的划分、记录的排列、索引的组织、信息的搜素
• 常见的文件物理结构
  顺序文件（连续存储）；链接文件；索引文件</code></pre>
<h3 id="分布式文件系统-DFS"><a href="#分布式文件系统-DFS" class="headerlink" title="分布式文件系统(DFS)"></a>分布式文件系统(DFS)</h3><pre><code>1. 体系架构  
• DFS实现的思路：  
  1）保证每台机器均可透明地访问其他机器上的文件（通过RPC调用）  
  2）将所有机器的文件系统关联起来，形成一个对外统一的整体  
• Client-Server Architectures：文件系统的挂载  
• Symmetric Architectures：通过特殊的hash算法将文件划分到各台机器上，需要访问文件时可根据hash算法进行定位
• Cluster-Based Distributed File Systems  
  主节点进行管理，从节点存储数据  
  文件切分成块，分散存储在从节点上  

2. 文件访问  
• 单机多进程访问同一文件：读写锁  
• 不同机器上进程访问同一文件  
• 注意临界区问题  

3. 备份与一致性  
• 客户端备份：Client-Server DFS  
• 服务器端备份：Cluster-Based DFS  

4. 容错管理  </code></pre>
<h3 id="Hadoop分布式文件系统-HDFS"><a href="#Hadoop分布式文件系统-HDFS" class="headerlink" title="Hadoop分布式文件系统(HDFS)"></a>Hadoop分布式文件系统(HDFS)</h3><pre><code>1. 设计考量
• HDFS：Hadoop Distributed File System 分布式文件系统
• MapReduce：并行计算框架
• 文件由数据块集合组成，每个数据块在本地文件系统中以单独文件进行存储

2. 体系结构</code></pre>
<p><img src="/img/202008052.png"></p>
<pre><code>• NameNode(masters)：每个集群一个名字节点，负责文件系统元数据操作、数据块的复制和定位
核心数据文件包括：元数据镜像文件、操作日志文件；元数据保存在内存中
• SecondaryNameNode(backups)：NameNode的备份节点 （防止Log过大回恢复时间过长 冷备份/离线）
“检查点”：定期从NameNode上下载镜像和日志，合并成新的，在本地保存，并写回NameNode
• DataNodes(slaves)：集群中每个节点一个数据节点，负责数据块的存储；为客户端提供实际文件数据
HDFS默认Block大小是64MB；若一个文件小于一个数据块的大小，并不占用整个数据块存储空间

3. 文件访问
• 文件写入HDFS
  NameNode告知客户端文件的每一个数据块存储在何处，客户端将数据块直接传输到指定的数据节点
• 数据存放策略（目标：负载均衡，快速访问，容错）
  三个副本：当前DataNode（快速写入）、不同机架（减少跨rack的网络流量）、相同机架其他节点（应对交换机故障）
  若有更多副本，随机节点
• 数据读取策略：从NameNode获得数据块不同副本的存放位置列表，最近者优先原则
• 文件访问模型：”一次写入多次读取“，不允许更改，仅容许追加；修改内容需删除重新写入;对于单文件只
               支持并发读，不支持并发写
  好处：避免读写冲突、无需文件锁

4. 备份与一致性
• HDFS数据备份优点
  1）加快数据传输速度
  2）容易检查数据错误
  3）保证数据的可靠性
• 一个文件有若干备份，写入成功的备份之间是强一致的

5. 容错机制
• DataNode故障：宕机，节点上所有的数据都会标记为不可读
• 定期检查备份因子：NameNode侦测DataNode故障，数据块自动复制到剩余的节点以保证满足备份因子
• NameNode故障：根据SecondaryNameNode中得FsImage和Editlog数据进行恢复</code></pre>
]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>笔记整理</tag>
      </tags>
  </entry>
  <entry>
    <title>【分布式系统_2】 MapReduce</title>
    <url>/2020/08/08/Distributed-System-2/Distributed-System-2/</url>
    <content><![CDATA[<h2 id="MapReduce批处理系统"><a href="#MapReduce批处理系统" class="headerlink" title="MapReduce批处理系统"></a>MapReduce批处理系统</h2><ol>
<li>Hadoop简介 —— Apache下的一个开源分布式计算平台<br> 基于Java语言开发，具有很好的跨平台特性  <ul>
<li>核心：分布式文件系统HDFS 和 MapReduce  </li>
<li>发展简史：Hadoop is from Yahoo.  </li>
<li>MapReduce在Hadoop中的位置：MapReduce是对并行计算的封装，将一个大的运算任务分解到集群的每个节点上，充分运用集群资源，缩短运行时间。</li>
</ul>
</li>
</ol>
<p><img src="/2020/08/08/Distributed-System-2/Distributed-System-2/202008081.png">  </p>
<ol start="2">
<li><p>体系结构</p>
<ul>
<li>Client<br>提交作业：用户编写的MapReduce程序通过Client提交到JobTracker端<br>作业监控：用户可通过Client提供一些接口查看作业的运行状态  </li>
<li>JobTracker<br>资源管理：监控TaskTracker与Job的状况（一旦发现失败，就将Task转移到其他节点）<br>作业调度：将Job拆分成Task，跟踪Task的执行进度、资源使用量等信息，由TaskScheduler调度  </li>
<li>TaskTracker<br>执行操作：接收JobTracker发送过来的命令并执行（如启动新Task、杀死Task等）<br>划分资源：使用“Slot”等量划分本节点上的资源量（CPU 、内存等），一个Task获取到一个Slot后才有机会运行<br>汇报信息：通过“心跳”将本节点上的资源使用情况和任务运行进度汇报给JobTracker  </li>
<li>Task进程<br>执行任务：Map Task &amp; Reduce Task;Jar包发送到TaskTracker，利用反射和代理机制动态加载代码  </li>
</ul>
</li>
<li><p>工作流程<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>map阶段 - shuffle阶段 - reduce阶段</strong>  </p>
</li>
</ol>
<ul>
<li>从节点角度看流程<br><img src="/2020/08/08/Distributed-System-2/Distributed-System-2/202008082.png">  </li>
</ul>
<ol>
<li>InputFormat: 定义了怎样与物理存储之间的映射，理想的分片大小是一个HDFS块  </li>
<li>Split: 逻辑概念，包含一些元数据信息。划分方法由用户决定  </li>
<li>Map: Hadoop为每个split创建一个Map任务，执行Map函数;Map任务数量：由Split的多少决定  </li>
<li>Shuffle:   <ul>
<li>Map端：写入缓存，溢写（分区、排序、合并_Combine）(局部), Key值相同的记录拼接在一起归并_Merge成文件到本地（一个Map节点的归并成一个文件）  </li>
<li>Reduce端: 领取数据，归并数据到缓存、本地（多个溢写文件的归并），数据输入给Reduce任务  </li>
</ul>
</li>
</ol>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5) Reduce:  执行Reduce函数;Reduce任务数量: 一般略小于reduce slot的数目，预留一些系统资源处理可能发生的错误<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6) OutputFormat: 与InputFormat对应  </p>
<ul>
<li>Hadoop序列化<br>  序列化：指把结构化对象转化为字节流以便在网络上传输或在磁盘上永久存储的过程<br>  序列化格式特点：紧凑、快速、可扩展、互操作<br>  Hadoop的序列化格式：Writable （数据类型一般为LongWritable、Text、IntWritable…）</li>
</ul>
<ol start="4">
<li>容错机制</li>
</ol>
<ul>
<li>代码错误  </li>
<li>机器故障<br>  1）Task容错：Map Task重新去HDFS读入数据，重新执行Map任务；Reduce Task重新去本地磁盘读入数据，重新执行Reduce任务<br>  2）TaskTracker容错：JobTracker接受不到“心跳”，安排其他TaskTracker重新运行<br>  3）JobTracker容错：单点故障，所有任务重新运行  </li>
</ul>
<h2 id="MapReduce编程"><a href="#MapReduce编程" class="headerlink" title="MapReduce编程"></a>MapReduce编程</h2><pre><code>1. 单个MapReduce
• 单元运算——WordCount程序任务
1）Map函数：处理输入、分词、组合键值对
   Map(K, V) &#123; For each word w in V :  Collect(w,1) &#125;
2）Combine函数：可选，Map内部先行合并
3）Reduce函数：按分区求和，处理输出
   Reduce的输入数据为&lt;Key,Iterable容器&gt;
   Reduce(K, V[ ]) &#123; For each v in V : count += v;    Collect(K, count); &#125;
4）Main函数：Job

• 二元运算（Join、集合交集、集合并集）
1）关系的自然连接（作业1-3）
   Map过程需要标记来自哪个关系表，Key值为连接属性。
   循环遍历 or 哈希实现

2. 组合式MapReduce
例：词频统计后，按词频范围划分组
划分为若干子任务，连续执行多个MapReduce，存在依赖关系（前一个Job做完后才能做下一个Job）
• 隐式依赖描述：定死顺序，且未考虑容错 
               runJob1(input , tmp);   runJob2(tmp, output);
• 显示依赖描述：调度灵活 更优
               Job3.addDepending(Job1)；设置依赖关系
               JobControl.addJob(Job1);     把多个job加入jobcontrol中

3. 链式MapReduce
例：词频统计后过滤掉词频较高的，且不修改词频统计程序
• 规则
整个Job中只能有一个Reducer，Reducer前面一个or多个Mapper，Reducer后面0个or多个Mapper
• 写法
ChainMapper.addMapper()   ChainReducer.setReducer()  ChainReducer.addMapper()

4. 迭代式MapReduce（Kmeans、PageRank）
• 迭代式任务的特征：
整个任务由一系列的子任务循环构成；子任务的执行操作完全相同；一个子任务的输出是下一个子任务的输入；
一个子任务是一个MapReduce Job
• 写法
While() &#123;   runIteration（） iter++； &#125;
• 性能瓶颈
每一迭代步结束时将结果写入HDFS，下一步将该结果再次从HDFS读出；
Map -&gt; 本地磁盘 -&gt; Reduce （I/O浪费、存储浪费）

5. Distributed Cache 
大表连接小表，将小表广播出去（小数据量-&gt;广播 ； 大数据量-&gt;本地，减少数据移动）</code></pre>
]]></content>
      <categories>
        <category>系统</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>笔记整理</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读_LEARNING TO REPRESENT PROGRAMS WITH GRAPHS(ICLR2018)</title>
    <url>/2020/09/08/ggnn/ggnn/</url>
    <content><![CDATA[<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在代码上进行任务学习，目前更多的是将自然语言的深度学习方法应用在代码上，这样会存在无法捕捉代码语义信息的问题，例如代码中变量、函数的长依赖在局部是难以学习到的。该文使用图来表达代码的语义和语法结构，使用基于图的深度学习方法来解释代码结构，增加了数据流和类型层级来弥补代码的语义损失。</p>
<h3 id="研究内容"><a href="#研究内容" class="headerlink" title="研究内容"></a>研究内容</h3><ul>
<li>如何构建源代码的程序图</li>
<li>如何将GGNN算法应用到这些大型图上</li>
</ul>
<h3 id="评估任务"><a href="#评估任务" class="headerlink" title="评估任务"></a>评估任务</h3><ul>
<li>VarNaming: 根据变量的用法预测变量名</li>
<li>VarMisuse: 根据在程序中的定位选择正确的变量名</li>
</ul>
<h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><h3 id="Graph-Structure"><a href="#Graph-Structure" class="headerlink" title="Graph Structure"></a>Graph Structure</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们用程序图来表示token之间的语法和语义关系，并且用不同类型的边来模拟token间的语法和语义关系。程序图的骨架是程序的抽象语法树(蓝色圆弧节点)，叶子结点表示为源码中的token(黑色方框)，如a图中所示，是”Assert.NotNull(clazz);”的表示。其中，共有两种有向边的形式：蓝线代表语义节点的连接，指向孩子节点；双黑线代表Token间的有序连接，指向下一个Token。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;图b是增加的数据流信息，一共有3种边的类型，LastWrite/LastUse/ComputedFrom，表现了控制数据在程序中传递的流向。还有一些特殊的数据流类型用于图的扩展，例如LastLexicalUse, ReturnsTo,FormalArgName等。<br><img src="/2020/09/08/ggnn/ggnn/20200090801.png"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后一点是，所有的节点和类型都double一下，便于网络中信息快速传播，但增加了模型建立的代价。</p>
<h3 id="GGNN-Gated-Graph-Nerual-Network"><a href="#GGNN-Gated-Graph-Nerual-Network" class="headerlink" title="GGNN - Gated Graph Nerual Network"></a>GGNN - Gated Graph Nerual Network</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;图G = (V,E,X)是由一系列节点V，节点特征X，以及一个有向边集合E组成，共有K个边的类型。  </p>
<ul>
<li>将每个节点v的特征表示为一个实值向量x，再将每个节点与一个状态向量h对应，用x来初始化，状态向量用于在图中传播消息，类型为k的消息会传播给v的邻居，消息是利用状态向量计算的，m=f(h)，这里f选用一个线性函数。  </li>
<li>通过在同一时间计算所有边的消息，所有的状态都同时被更新。节点v的新状态是通过聚集所有进入的消息来计算的，这里通过一个简单的加和函数作为聚合方法计算新状态m’。  </li>
<li>给出了聚合后的消息和当前状态的向量，下一时刻的状态h’=GRU(m’. h)，GRU是LSTM的变体，一个门控循环单元。</li>
</ul>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以上过程重复固定的时间步，然后将最后一步得到的状态向量当做节点的向量表示。  </p>
<h3 id="Implement"><a href="#Implement" class="headerlink" title="Implement"></a>Implement</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对已知变量的类型信息进行embedding，若未知则定义为”UNKTYPE”标识。节点的初始状态由token和type的语义信息共同决定，token还会被切分为subtoken，然后将每个subtoken的表示取平均来得到token的表示，最后将这个表示和之前的类型表示相连接，通过一个线性层来的到每个节点的初始表示。  </p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于<strong>VarNaming</strong>任务，给定一个程序和一个目标变量，建立上述的程序图并把该变量的名字用<SLOT>替换，为了预测其名字，利用初始节点标签来运行GGNN 8个时间步，计算出所有<SLOT>表示的平均值来作为变量的表示，这个表示就被用作一个单层GRU的初始状态，以subtoken的形式预测目标名字。  </SLOT></SLOT></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于<strong>VarMisuse</strong>任务，检测误用即预测是否一致，将想要预测的某位置的token称为槽，从候选变量集合中选择正确的token。该任务需要修改图结构，首先，为了计算槽t的上下文表示 c(t)，我们在t的位置插入一个新的结点v&lt;SLOT&gt; ，当作这里有一个“洞”，然后将它与的剩下部分用除LastUse, LastWrite, LastLexicalUse和GuardedBy边之外的所有边相连。然后，为了计算目标槽的每个候选变量的表示u(t,v)，我们将每个候选集中的v插入图中，然后为它们连LastUse, LastWrite, LastLexicalUse边。利用初始结点的表示加上一个额外候选结点的表示，运行GGNN 8次，得到了结点的最终状态。最后通过argmax来初始节点和额外节点的连接线性层，利用max-margin objective来进行训练。  </p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实现部分并未涉及到具体的模型细节，例如参数量、subtoken数量、token的embedding方法和超参数的设置等。无参考源码。</p>
<h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>该工作为VarMisuse收集了一个开源C#数据集，挑选了Github上星最多且能完整编译的29个不同领域的项目，代码量共计290多万行，并对所有使用变量的位置进行数据收集，过滤掉变量声明。其任务就是从一些类型正确的变量中推断出某位置原本的变量。</p>
<h3 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h3><ul>
<li>VarNaming: 使用ABGLBL作为基准模型(使用每个变量用法的4个左右上下文标注的对数双线性模型)</li>
<li>VarMisuse: 使用双向GRU作为基准模型，以AVGBIRNN作为加强版(对变量取平均)</li>
</ul>
<h3 id="Quantitative"><a href="#Quantitative" class="headerlink" title="Quantitative"></a>Quantitative</h3><p>两个任务的评估结果：<br><img src="/2020/09/08/ggnn/ggnn/20200090802.png"><br>下图是不同边和结点表示对结果的影响，从表中可以看出如果只保留语法信息会对varNaming任务产生很大影响。<br><img src="/2020/09/08/ggnn/ggnn/20200090803.png"> </p>
<h3 id="Qualitative"><a href="#Qualitative" class="headerlink" title="Qualitative"></a>Qualitative</h3><p>下图展示了对不同位置的变量名预测的结果：<br><img src="/2020/09/08/ggnn/ggnn/20200090804.png"> </p>
<p>使用VarMisuse还发现了开源项目中存在的变量命名误用bug，便于修正。</p>
<h1 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然源代码在其他学科（如编程语言研究）中有很好的理解和研究，但它是深度学习的一个相对较新的领域。 与文本或知觉数据相比，它提供了新的角度，因为它的（本地）语义是明确定义的，并且可以使用众所周知的高效程序分析来提取丰富的附加信息。 另一方面，整合这些丰富的结构化信息带来了一个有趣的挑战。因为它需要概率地提炼类型系统中包含的标准信息， 我们认为它是学习源代码含义的核心挑战的第一个尝试。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>M. Allamanis, M. Brockschmidt, and M. Khademi, “Learning to represent programs with graphs,” in International Conference on Learning Representations, 2018.<br>Y. Li, D. Tarlow, M. Brockschmidt, and R. Zemel, “Gated graph sequence neural networks,” arXiv preprint arXiv:1511.05493, 2015.<br><a href="https://blog.csdn.net/m0_37924639/article/details/80499416">https://blog.csdn.net/m0_37924639/article/details/80499416</a><br><a href="https://zhuanlan.zhihu.com/p/36117802">https://zhuanlan.zhihu.com/p/36117802</a>  </p>
]]></content>
      <categories>
        <category>Big Code</category>
      </categories>
      <tags>
        <tag>paper</tag>
        <tag>Code Naturalness</tag>
      </tags>
  </entry>
  <entry>
    <title>CodeSearchDataset</title>
    <url>/2020/09/24/CodeSearchDataset/CodeSearchDataset/</url>
    <content><![CDATA[<h1 id="Code-Search数据集调研"><a href="#Code-Search数据集调研" class="headerlink" title="Code Search数据集调研"></a>Code Search数据集调研</h1><blockquote>
<p>Code Search是代码任务中的一项关键问题，根据给出的Query文本匹配最接近的代码回答。例如，”How do i iterate through a hashmap?”，代码搜索模型会在代码语料库中进行搜索，返回匹配的代码段。根据[1]中的统计,近几年对于代码搜索模型的研究逐渐增多，任务对应的数据集也丰富起来，先后出现了多个数据集benchmark，这些benchmark的目的都在于想统一代码搜索任务的评估方式，但也都略有区别。近期对代码搜搜的任务进行了一些调研，在此做一个整理。</p>
</blockquote>
<h3 id="CODEnn-DataSet-2018"><a href="#CODEnn-DataSet-2018" class="headerlink" title="CODEnn DataSet (2018)"></a>CODEnn DataSet (2018)</h3><p>CODEnn数据集是DeepCS[2]系统所使用的大规模数据集，包含了代码和对应的文本表述，对应CODEnn模型的输入需要，数据集以&lt;method name, API dequence, tokens, description&gt;元组存储,该数据可在<a href="https://drive.google.com/drive/folders/1GZYLT_lzhlVczXjD6dgwVUvDDPHMB6L7%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://drive.google.com/drive/folders/1GZYLT_lzhlVczXjD6dgwVUvDDPHMB6L7上获取。</a><br><img src="/2020/09/24/CodeSearchDataset/CodeSearchDataset/2020092403.png"><br>CODEnn选取了Stack Overflow上高星的50个有关Java程序的提问，构造了代码搜索的查询测试集。</p>
<p>由于数据集格式的固定，该数据集只够于以token方式处理代码的模型，因此存在一定的限制。</p>
<h3 id="Nerual-Neural-Code-Search-Evaluation-Dataset-2019"><a href="#Nerual-Neural-Code-Search-Evaluation-Dataset-2019" class="headerlink" title="Nerual Neural Code Search Evaluation Dataset(2019)"></a>Nerual Neural Code Search Evaluation Dataset(2019)</h3><p>该数据集由Facebook于2019年推出，整个数据集分为三个部分：<br><strong>GitHub存储库</strong><br>由GitHub上近24549个星数最高的Android库的代码片段组成的搜索语料库，包含Python脚本。  </p>
<p><strong>搜索语料库</strong><br>依靠前面的24549个库，解析其中的方法主体，总共包括4,716,814个。给到自然语言query后，代码搜索模型从中搜索出需要的代码片段。<br>每个方法主体已经给到了包括它的ID、文件路径、起始行、结束行、url等在内的相关信息。<br><img src="/2020/09/24/CodeSearchDataset/CodeSearchDataset/2020092404.png">  </p>
<p><strong>评估数据集</strong><br>包含287个堆栈溢出问答对，包括其ID、问题、答案url、答案几个部分，这些问题来自Stack Exchange。</p>
<p>目前，该团队基于这个数据集评估了NCS,UNIF两个模型，其中UNIF以简单的模型结构超过了CODEnn在代码搜索任务上的表现。在该数据集上，语料库的作用仅仅是训练代码的表征，当代码和文本使用同一表征模型时适用。如果需要有监督的训练，或进行bi-modal模型的训练，则必须要对语料库增加对应的文本描述。</p>
<h3 id="CodeSearchNet-2020"><a href="#CodeSearchNet-2020" class="headerlink" title="CodeSearchNet(2020)"></a>CodeSearchNet(2020)</h3><p>GitHub发起了CodeSearchNet挑战赛，以推动用自然语言搜索程序代码的技术发展。CodeSearchNet语料库是一个庞大的程序代码和自然语言批注数据集，让研究人员可用来训练机器学习模型。该数据集收集了大量以Go、Java、JavaScript、PHP、Python和Ruby程序语言撰写的函式数据集，以及其说明文件，官方使用解析器TreeSitter作为基础架构，并发布了数据预处理工作管线，作为其他研究人员在程序代码中应用机器学习的起点。<br>数据集的组成如下图所示：<br><img src="/2020/09/24/CodeSearchDataset/CodeSearchDataset/2020092406.png"> </p>
<p>CodeSearchNet是一个比较完善的代码搜索数据库，且有相对应的评估系统，目前有codebert、code2vec等模型在该数据及上进行代码搜索的任务学习。</p>
<h3 id="CosBench-2020"><a href="#CosBench-2020" class="headerlink" title="CosBench(2020)"></a>CosBench(2020)</h3><p>tbc…</p>
<h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><p>[1]Are the Code Snippets What We Are Searching for?A Benchmark and an Empirical Study on CodeSearch with Natural-Language Queries<br>[2]Deep Code Search<br>[3]Nerual Neural Code Search Evaluation Dataset<br>[4]<a href="https://zhuanlan.zhihu.com/p/85159018">https://zhuanlan.zhihu.com/p/85159018</a><br>[5]<a href="https://github.com/facebookresearch/Neural-Code-Search-Evaluation-Dataset">https://github.com/facebookresearch/Neural-Code-Search-Evaluation-Dataset</a><br>[6]<a href="https://github.com/github/CodeSearchNet">https://github.com/github/CodeSearchNet</a><br>[7]<a href="https://wandb.ai/github/codesearchnet/benchmark">https://wandb.ai/github/codesearchnet/benchmark</a>  </p>
]]></content>
      <categories>
        <category>Big Code</category>
      </categories>
      <tags>
        <tag>paper</tag>
        <tag>Code Naturalness</tag>
      </tags>
  </entry>
</search>
